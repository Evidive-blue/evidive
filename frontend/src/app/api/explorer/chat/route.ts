import { NextRequest, NextResponse } from "next/server";

const GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions";

const SYSTEM_PROMPT = `Tu es DiveGuide, un assistant expert en plongÃ©e sous-marine pour EviDive. Tu aides les utilisateurs Ã  dÃ©couvrir le monde sous-marin et Ã  trouver leurs prochaines aventures de plongÃ©e.

TON RÃ”LE :
- Tu poses des questions pour comprendre le profil et les envies de l'utilisateur
- Tu es passionnÃ©, chaleureux et enthousiaste
- Tu donnes des conseils personnalisÃ©s basÃ©s sur leurs rÃ©ponses
- Tu adaptes ta langue Ã  celle de l'utilisateur (franÃ§ais ou anglais selon son premier message)

DÃ‰ROULEMENT :
1. Commence par te prÃ©senter briÃ¨vement et demander si l'utilisateur a dÃ©jÃ  fait de la plongÃ©e
2. Selon sa rÃ©ponse, adapte tes questions suivantes
3. Pose des questions sur son expÃ©rience, ses envies, ses contraintes
4. AprÃ¨s 4-5 Ã©changes, propose des recommandations personnalisÃ©es

STYLE :
- Questions ouvertes, rÃ©ponses concises
- Utilise des emojis avec modÃ©ration (ðŸ¢ ðŸ¦ˆ ðŸŒŠ ðŸ¤¿)
- Sois encourageant et bienveillant`;

const WELCOME_FR =
  "Bonjour ! Je suis DiveGuide, ton assistant personnel pour la plongÃ©e. ðŸŒŠ\n\nAs-tu dÃ©jÃ  fait de la plongÃ©e ? Si oui, quel est ton niveau ? Sinon, dis-moi ce qui t'attire dans les fonds marins !";
const WELCOME_EN =
  "Hello! I'm DiveGuide, your personal diving assistant. ðŸŒŠ\n\nHave you ever been diving? If so, what's your level? If not, tell me what attracts you to the underwater world!";

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const messages = Array.isArray(body?.messages) ? body.messages : [];

    const apiKey = process.env.GROQ_API_KEY;

    if (!apiKey) {
      return NextResponse.json({
        message: messages.length === 0 ? WELCOME_FR : "Le service IA n'est pas configurÃ©. Ajoutez GROQ_API_KEY dans votre .env.",
      });
    }

    if (messages.length === 0) {
      const locale = request.headers.get("accept-language")?.includes("fr")
        ? "fr"
        : "en";
      return NextResponse.json({
        message: locale === "fr" ? WELCOME_FR : WELCOME_EN,
      });
    }

    if (messages.length > 50) {
      return NextResponse.json(
        { error: "Trop de messages." },
        { status: 400 }
      );
    }

    const apiMessages = [
      { role: "system" as const, content: SYSTEM_PROMPT },
      ...messages.map((m: { role: string; content: string }) => ({
        role: m.role as "user" | "assistant",
        content: String(m.content).slice(0, 2000),
      })),
    ];

    const response = await fetch(GROQ_API_URL, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile",
        messages: apiMessages,
        temperature: 0.8,
        max_tokens: 500,
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      console.error("Groq API error:", error);
      return NextResponse.json(
        { error: "Erreur du service IA" },
        { status: 500 }
      );
    }

    const data = (await response.json()) as {
      choices?: Array<{ message?: { content?: string } }>;
    };
    const assistantMessage = data.choices?.[0]?.message?.content;

    if (!assistantMessage) {
      return NextResponse.json(
        { error: "RÃ©ponse vide du service IA" },
        { status: 500 }
      );
    }

    return NextResponse.json({ message: assistantMessage });
  } catch (error) {
    console.error("Chat API error:", error);
    return NextResponse.json(
      { error: "Erreur serveur" },
      { status: 500 }
    );
  }
}
